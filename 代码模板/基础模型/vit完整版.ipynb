{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "599bf2d4-2fa5-420f-a5b9-32d86c9f46d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'einops'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meinops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rearrange\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#图像及模型处理\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01md2l\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m torch \u001b[38;5;28;01mas\u001b[39;00m d2l\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'einops'"
     ]
    }
   ],
   "source": [
    "#导入模型计算基本包\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from einops import rearrange\n",
    "#图像及模型处理\n",
    "from d2l import torch as d2l\n",
    "import torchvision\n",
    "#评估绘图包\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "#设置环境变量免责声明\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290d72a4-4962-45c5-9b2a-2e0fc689cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置参数\n",
    "device = d2l.try_gpu()#设置运行模式：CPU/GPU\n",
    "batch_size, lr, num_epochs = 16, 0.005, 20#设置批量、学习率和迭代次数\n",
    "data_dir = '../../数据/'#设置文件读取路径\n",
    "save_dir = './model_ViT_.pt'#设置保存路径\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.Resize((768, 768)),\n",
    "                                            torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])#图像归一化方式\n",
    "input_shape = (3, 768, 768)\n",
    "num_patches, dim, depth, heads, mlp_dim = 48, 64, 6, 8, 128#保证num_patches可整除image_shape\n",
    "#在网络参数方面，使用了 64 个单元的维度，6 个 Transformer 块的深度，8 个 Transformer 头，MLP 使用 128 维度\n",
    "num_classes = 2#输出类别数量\n",
    "\n",
    "#设置随机数种子\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af81a0-f9fa-4168-b53c-a7b6cade00cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "\t#  下面两个常规设置了，用来np和random的话要设置 \n",
    "    np.random.seed(seed) \n",
    "    random.seed(seed)\n",
    "    \n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # 禁止hash随机化\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'  # 在cuda 10.2及以上的版本中，需要设置以下环境变量来保证cuda的结果可复现\n",
    "    \n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # 多GPU训练需要设置这个\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    torch.use_deterministic_algorithms(True) # 一些操作使用了原子操作，不是确定性算法，不能保证可复现，设置这个禁用原子操作，保证使用确定性算法\n",
    "    torch.backends.cudnn.deterministic = True  # 确保每次返回的卷积算法是确定的\n",
    "    torch.backends.cudnn.enabled = False  # 禁用cudnn使用非确定性算法\n",
    "    torch.backends.cudnn.benchmark = False  # 与上面一条代码配套使用，True的话会自动寻找最适合当前配置的高效算法，来达到优化运行效率的问题。False保证实验结果可复现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ce9dd-edbc-47f9-8576-6fed6912f831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#残差模块，放在每个前馈网络和注意力之后\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(x, **kwargs) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbe0cfb-95e5-49dc-994f-d6864b106724",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layernorm归一化,放在多头注意力层和激活函数层。用绝对位置编码的BERT，layernorm用来自身通道归一化\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cfe8a1-aecb-4859-8340-898fedc4e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#放置多头注意力后，因为在于多头注意力使用的矩阵乘法为线性变换，后面跟上由全连接网络构成的FeedForward增加非线性结构\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd96c5a-8632-4016-b6fa-907a243b09f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#多头注意力层，多个自注意力连起来。使用qkv计算\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads=8):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        self.scale = dim ** -0.5\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, dim * 3, bias=False)\n",
    "        self.to_out = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "        qkv = self.to_qkv(x)\n",
    "        q, k, v = rearrange(qkv, 'b n (qkv h d) -> qkv b h n d', qkv=3, h=h)\n",
    "\n",
    "        dots = torch.einsum('bhid,bhjd->bhij', q, k) * self.scale\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = F.pad(mask.flatten(1), (1, 0), value = True)\n",
    "            assert mask.shape[-1] == dots.shape[-1], 'mask has incorrect dimensions'\n",
    "            mask = mask[:, None, :] * mask[:, :, None]\n",
    "            dots.masked_fill_(~mask, float('-inf'))\n",
    "            del mask\n",
    "\n",
    "        attn = dots.softmax(dim=-1)\n",
    "\n",
    "        out = torch.einsum('bhij,bhjd->bhid', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        out =  self.to_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219fc1c4-999d-4c6f-aa1e-d4df99957161",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, mlp_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                Residual(PreNorm(dim, MSA(dim, n_heads))),\n",
    "                Residual(PreNorm(dim, FeedForward(dim, mlp_dim)))\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x, mask=mask)\n",
    "            x = ff(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5af333c-e47d-4e94-8107-2ac39cd11c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将图像切割成一个个图像块,组成序列化的数据输入Transformer执行图像分类任务。\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, input_shape, num_patches, dim, depth, heads, mlp_dim, num_classes):\n",
    "        super().__init__()\n",
    "        channels, image_size, image_size0 = input_shape\n",
    "        assert input_shape[1] % num_patches == 0, \"Input shape not entirely divisible by number of patches\"\n",
    "        assert input_shape[2] % num_patches == 0, \"Input shape not entirely divisible by number of patches\"\n",
    "        patch_size = input_shape[1] / num_patches\n",
    "        patch_dim = channels * patch_size ** 2\n",
    "        num_patches = num_patches ** 2\n",
    "\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        self.patch_to_embedding = nn.Linear(patch_dim, dim)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.transformer = Transformer(dim, depth, heads, mlp_dim)\n",
    "\n",
    "        self.to_cls_token = nn.Identity()\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.Linear(dim, mlp_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(mlp_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img, mask=None):\n",
    "        p = self.patch_size\n",
    "\n",
    "        x = rearrange(img, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = p, p2 = p)\n",
    "        x = self.patch_to_embedding(x)\n",
    "\n",
    "        cls_tokens = self.cls_token.expand(img.shape[0], -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding\n",
    "        x = self.transformer(x, mask)\n",
    "\n",
    "        x = self.to_cls_token(x[:, 0])\n",
    "        return self.mlp_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6032b4e5-2900-4e7a-acbb-3a99aac15fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#精度评估函数\n",
    "def evaluate_accuracy_gpu(net, data_iter, device=None):\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    metric = d2l.Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            metric.add(d2l.accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c74fdc7-1ecd-4d0e-bdd1-f5ab3e6dd3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练函数\n",
    "def train(net, train_iter, test_iter, num_epochs, lr, device):\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    optimizer = Adam(net.parameters(), lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n",
    "                            legend=['train loss', 'train acc', 'test acc'])\n",
    "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
    "    for epoch in range(num_epochs):\n",
    "        metric = d2l.Accumulator(3)\n",
    "        net.train()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
    "            timer.stop()\n",
    "            train_l = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,\n",
    "                             (train_l, train_acc, None))\n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    "    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n",
    "          f'test acc {test_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n",
    "          f'on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf89fc8-ac66-459d-a715-a9b2c2c4aec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制多分类ROC曲线\n",
    "def plot_multiclass_roc_curve(model, test_iter):\n",
    "    # 获取模型的预测概率和真实标签\n",
    "    y_true = []\n",
    "    y_prob = []\n",
    "    for batch in test_iter:\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.cuda()\n",
    "        outputs = model(inputs)\n",
    "        probabilities = outputs.softmax(dim=1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_prob.extend(probabilities.cpu().detach().numpy())\n",
    "    y_true = np.array(y_true)\n",
    "    y_prob = np.argmax(y_prob,axis=1)\n",
    "    y_prob = np.array(y_prob)\n",
    "\n",
    "    #微平均和宏平均方法（Micro-average and Macro-average）\n",
    "    # 将真实标签转换为二值矩阵\n",
    "    y_true = label_binarize(y_true, classes=np.unique(y_true))\n",
    "    y_prob = label_binarize(y_prob, classes=np.unique(y_prob))\n",
    "\n",
    "    # 将多分类问题转换为二分类问题\n",
    "    y_true = y_true.ravel()\n",
    "    y_prob = y_prob.ravel()\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # 绘制ROC曲线\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca6e51a-557f-4db4-992e-2d5a227a7baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #数据处理\n",
    "    train_path = data_dir + '/training'\n",
    "    test_path = data_dir + '/testing'\n",
    "    \n",
    "    train_data = torchvision.datasets.ImageFolder(train_path,transform=transform)\n",
    "    test_data = torchvision.datasets.ImageFolder(test_path,transform=transform)\n",
    "\n",
    "    train_iter=torch.utils.data.DataLoader(train_data,batch_size=batch_size,shuffle=True)\n",
    "    test_iter=torch.utils.data.DataLoader(test_data,batch_size=batch_size,shuffle=True)\n",
    "    \n",
    "    #定义模型和训练模块\n",
    "    model = ViT(input_shape, num_patches, dim, depth, heads, mlp_dim, num_classes)\n",
    "\n",
    "    #训练\n",
    "    train(model, train_iter, test_iter, num_epochs, lr, device)\n",
    "    \n",
    "    #保存模型\n",
    "    torch.save(model,save_dir)\n",
    "\n",
    "    #调用模型计算ROC曲线\n",
    "    plot_multiclass_roc_curve(model, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b11ab-9bae-4967-996a-489e55944b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
