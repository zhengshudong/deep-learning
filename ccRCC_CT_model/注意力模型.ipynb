{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29d23ba8-5dd8-4c4f-a52a-ce72798143f6",
   "metadata": {},
   "source": [
    "基本库导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0709478-2165-4147-a835-907d573746c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4962aaa-d1a4-48dc-a35c-ae8d0096373e",
   "metadata": {},
   "source": [
    "模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bc8305-4f4b-4acb-9d2b-3806520a5af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 残差流\n",
    "class RestNetBasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super(RestNetBasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=[3,3,3], stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=[3,3,3], stride=stride, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        tmp = self.bn1(output)\n",
    "        output = F.relu(tmp)\n",
    "        output = self.conv2(output)\n",
    "        output = self.bn2(output)\n",
    "        return F.relu(x + output)\n",
    "    \n",
    "class RestNetDownBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super(RestNetDownBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=stride[0], padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=stride[1], padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
    "        self.extra = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=stride[0], padding=0),\n",
    "            nn.BatchNorm3d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        extra_x = self.extra(x)\n",
    "        output = self.conv1(x)\n",
    "        out = F.relu(self.bn1(output))\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        return F.relu(extra_x + out)\n",
    "    \n",
    "class RestNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(RestNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(1, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = nn.Sequential(RestNetBasicBlock(64, 64, 1),\n",
    "                                    RestNetBasicBlock(64, 64, 1))\n",
    "\n",
    "        self.layer2 = nn.Sequential(RestNetDownBlock(64, 128, [2, 1]),\n",
    "                                    RestNetBasicBlock(128, 128, 1))\n",
    "\n",
    "        self.layer3 = nn.Sequential(RestNetDownBlock(128, 256, [2, 1]),\n",
    "                                    RestNetBasicBlock(256, 256, 1))\n",
    "\n",
    "        self.layer4 = nn.Sequential(RestNetDownBlock(256, 512, [2, 1]),\n",
    "                                    RestNetBasicBlock(512, 512, 1))\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d(output_size=(1,1,1))\n",
    "\n",
    "    def forward(self, x):  \n",
    "        # [1, 3, 224, 224]\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        # [1, 64, 112, 112]\n",
    "        \n",
    "        out = self.layer1(out)\n",
    "        # [1, 64, 112, 112]\n",
    "        \n",
    "        out = self.layer2(out)\n",
    "        # [1, 128, 56, 56]\n",
    "        \n",
    "        out = self.layer3(out)\n",
    "        # [1, 256, 28, 28]\n",
    "        \n",
    "        out = self.layer4(out)\n",
    "        # [1, 512, 14, 14]\n",
    "        \n",
    "        out = self.avgpool(out)\n",
    "        # [1, 512, 1, 1]\n",
    "        \n",
    "        out = out.view(x.shape[0], -1)\n",
    "        # [1, 512]\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877cbbc7-e633-4c6e-8ef2-0d18037d5397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线性流\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(60660, 32768)\n",
    "        self.fc2 = nn.Linear(32768, 8192)\n",
    "        self.fc3 = nn.Linear(8192, 2048)\n",
    "        self.fc4 = nn.Linear(2048, 512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc4(self.fc3(self.fc2(self.fc1(x))))\n",
    "        return F.relu(out)\n",
    "    # [1, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67a14d8-dcea-4208-a3b7-0f8f1f55aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class merge_Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, data_len, drop):\n",
    "        \n",
    "        super(merge_Attention, self).__init__()\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "        self.query = nn.Linear(data_len, data_len)\n",
    "        self.key = nn.Linear(data_len, data_len)\n",
    "        self.value = nn.Linear(data_len, data_len)\n",
    "        self.c_proj = nn.Linear(data_len, data_len)\n",
    "        \n",
    "    def forward(self, x_dicom, x_data):\n",
    "\n",
    "        #x shape: (batch_size, data_len)\n",
    "        query = self.query(x_dicom)\n",
    "        key = self.key(x_data)        \n",
    "        value = self.value(x_dicom)   \n",
    "        \n",
    "        # (batch_size, data_len) --> (batch_size, data_len, 1)\n",
    "        query = query.unsqueeze(2)\n",
    "        key = key.unsqueeze(2)\n",
    "        value = value.unsqueeze(2)\n",
    "        \n",
    "        # (batch_size, data_len, 1) matmul (batch_size, 1, data_len) --> (batch_size, data_len, data_len)\n",
    "        scores = torch.matmul(query, key.permute(0,2,1)) / math.sqrt(query.size(-1))\n",
    "        weights = F.softmax(scores, dim = -1)           # (batch_size, data_len, data_len)\n",
    "        weights = self.dropout(weights)\n",
    "        \n",
    "        # (batch_size, data_len, data_len) matmul (batch_size, data_len, 1) --> (batch_size, data_len, 1)\n",
    "        context = torch.matmul(weights, value)\n",
    "        \n",
    "        # (batch_size, data_len, 1) --> (batch_size, data_len)\n",
    "        interacted = context.contiguous().view(context.shape[0], -1)\n",
    "        interacted = self.c_proj(interacted)\n",
    "        \n",
    "        return interacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c99a9c-2521-4142-9ecc-8cb0ea8b8bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隐藏层\n",
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, data_len, middle_dim, drop):\n",
    "        super(FeedForward, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(data_len, middle_dim)\n",
    "        self.fc2 = nn.Linear(middle_dim, data_len)\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.fc2(self.dropout(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e76037e-2047-46b5-bf96-af5cb5d4d44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 融合层\n",
    "class attentionmerge(nn.Module):\n",
    "    \n",
    "    def __init__(self, data_len, middle_dim, drop, num_class):\n",
    "        super(attentionmerge, self).__init__()\n",
    "        \n",
    "        self.resnet = RestNet(num_class)\n",
    "        self.densenet = DenseNet()\n",
    "        self.attention = merge_Attention(data_len, drop)\n",
    "        self.layernorm = nn.LayerNorm(data_len)\n",
    "        self.feedforward = FeedForward(data_len, middle_dim, drop)\n",
    "        self.fc = nn.Linear(data_len, num_class)\n",
    "    \n",
    "    def forward(self, x_dicom, x_data):\n",
    "        y_dicom = self.resnet(x_dicom)\n",
    "        # [batch, 512]\n",
    "        \n",
    "        y_data = self.densenet(x_data)\n",
    "        # [batch, 512]\n",
    "        \n",
    "        interacted = self.attention(y_dicom, y_data)\n",
    "        interacted = self.layernorm(interacted + y_dicom)\n",
    "        y = self.feedforward(interacted)\n",
    "        y = self.layernorm(y + interacted)\n",
    "        # [batch, data_len]\n",
    "        \n",
    "        out = self.fc(y)\n",
    "        # [batch, num_class]\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1641c21-58bd-4144-b333-19b3931ec97a",
   "metadata": {},
   "source": [
    "迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f8516c-ed3a-4991-92ae-241d74cf55cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, epoch):\n",
    "    metric = Accumulator(3)\n",
    "    model.train()\n",
    "    model = model.to(device)\n",
    "    iter_time = time.time()\n",
    "    i=0\n",
    "    for x_dicom, x_data, y in train_loader:\n",
    "        i+=1\n",
    "        x_dicom = x_dicom.to(device)\n",
    "        x_data = x_data.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        out = model(x_dicom, x_data)\n",
    "        loss = criterion(out, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            metric.add(loss * y.shape[0], accuracy(out, y), y.shape[0])\n",
    "\n",
    "        train_l = metric[0] / metric[2]\n",
    "        train_acc = metric[1] / metric[2]\n",
    "\n",
    "        if ((i+1) % 5 == 0 and i!=0) or i==len(train_loader)-1:\n",
    "            tnow = time.time()\n",
    "            iter_dt = tnow - iter_time\n",
    "            iter_time = tnow\n",
    "            print(\"Epoch [{}][{}/{}]  Loss: {:.5f}  accuracy: {:.5f}  time: {:.2f}s\".format(epoch, i+1, \n",
    "                                                                                            len(train_loader), train_l,\n",
    "                                                                                            train_acc, iter_dt))\n",
    "            f = open(\"training_data_attention.txt\", \"a\")\n",
    "            f.write(\"Epoch [{}][{}/{}]  Loss: {:.5f}  accuracy: {:.5f}  time: {:.2f}s\".format(epoch, i+1, \n",
    "                                                                                              len(train_loader), train_l,\n",
    "                                                                                              train_acc, iter_dt)+'\\n')\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45855a8e-193b-4fa6-a755-6760a919d102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数初始化\n",
    "def _init_weights(module):\n",
    "    # isinstance用于判断第一个参数是否是第二个参数的实例\n",
    "    # 对Linear层初始化\n",
    "    if isinstance(module, nn.Linear):\n",
    "        torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "        if module.bias is not None:\n",
    "            torch.nn.init.zeros_(module.bias)\n",
    "    elif isinstance(module, nn.LayerNorm):\n",
    "        # 对LayerNorm层初始化\n",
    "        torch.nn.init.zeros_(module.bias)\n",
    "        torch.nn.init.ones_(module.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e41247-c893-44fc-b3a5-c899941372b9",
   "metadata": {},
   "source": [
    "优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bed6c2-b6c6-422b-b5b9-4844e68eec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_optimizers(model, lr, weight_decay):\n",
    "        decay = set()\n",
    "        no_decay = set()\n",
    "        # 通常来说我们只对线性层做weight decay, 主要是Attention\n",
    "        whitelist_weight_modules = (torch.nn.Linear, )\n",
    "        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Conv3d,\n",
    "                                    torch.nn.BatchNorm3d, torch.nn.Conv2d,\n",
    "                                    torch.nn.MaxPool2d, torch.nn.AdaptiveAvgPool2d,\n",
    "                                    torch.nn.BatchNorm2d)\n",
    "        for mn, m in model.named_modules():\n",
    "        # 遍历模型参数, mn是Moudle name m是Moudle\n",
    "            for pn, p in m.named_parameters():\n",
    "                fpn = '%s.%s' % (mn, pn) if mn else pn # 完整的参数名称\n",
    "                if pn.endswith('bias'):\n",
    "                    no_decay.add(fpn)\n",
    "                elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):\n",
    "                    decay.add(fpn)\n",
    "                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):\n",
    "                    no_decay.add(fpn)\n",
    "\n",
    "        # 判断有没有参数既被判定需要weight decay又被判定不需要(同时存在于两个集合当中)\n",
    "        param_dict = {pn: p for pn, p in model.named_parameters()}\n",
    "        inter_params = decay & no_decay\n",
    "        union_params = decay | no_decay\n",
    "        assert len(inter_params) == 0, \"parameters %s made it into both decay/no_decay sets!\" % (str(inter_params), )\n",
    "        assert len(param_dict.keys() - union_params) == 0, \"parameters %s were not separated into either decay/no_decay set!\" \\\n",
    "                                                    % (str(param_dict.keys() - union_params), )\n",
    "\n",
    "        # 创建 PyTorch 优化器对象\n",
    "        optim_groups = [\n",
    "            {\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": weight_decay},\n",
    "            {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0}]\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77ebe71-233c-4e01-927d-602c0be3e660",
   "metadata": {},
   "source": [
    "精度函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159fbe3-a536-4cf1-aea0-ebce1e287f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计数器\n",
    "class Accumulator:\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a9c69-603e-4837-9cea-14766b305b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5deb76-f892-4f0b-8e57-fd4c8dd7a8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy_gpu(model, data_iter, device=None):\n",
    "    if isinstance(model, nn.Module):\n",
    "        model.eval()\n",
    "        if not device:\n",
    "            device = next(iter(model.parameters())).device\n",
    "    metric = Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for x_dicom, x_data, y in data_iter:\n",
    "            if isinstance(x_dicom, list):\n",
    "                x_dicom = [x_dicom.to(device) for x in x_dicom]\n",
    "            else:\n",
    "                x_dicom = x_dicom.to(device)\n",
    "            if isinstance(x_data, list):\n",
    "                x_data = [x_data.to(device) for x in x_data]\n",
    "            else:\n",
    "                x_data = x_data.to(device)\n",
    "            y = y.to(device)\n",
    "            metric.add(accuracy(model(x_dicom, x_data), y), y.numel())\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b15a0d9-2def-43d5-a19e-ab9af462b010",
   "metadata": {},
   "source": [
    "数据集载入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2dc859-e3a3-4f7c-9a51-5dd141742741",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_Dataset(Dataset):\n",
    "    def __init__(self, data1_path, data2_path,label_path, transform=None):\n",
    "        super(Dataset,self).__init__()\n",
    "        self.feature1 = torch.from_numpy(np.load(data1_path)).float()\n",
    "    \n",
    "        self.feature2 = torch.from_numpy(np.load(data2_path)).float()\n",
    "        self.label = torch.from_numpy(np.load(label_path)).long()\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return self.feature1.shape[0]\n",
    "    def __getitem__(self, item):\n",
    "        X1 = self.feature1[item]\n",
    "        X2 = self.feature2[item]\n",
    "        y = self.label[item]\n",
    "        if self.transform:\n",
    "            X1 = self.transform(X1)\n",
    "            X2 = self.transform(X2)\n",
    "        return X1,X2,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f900b9-69b7-475c-8daa-6bdd53c8f311",
   "metadata": {},
   "source": [
    "参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d70bcb8-2a06-4adf-a31f-8a7253b04d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_len = 512\n",
    "middle_dim = 2048\n",
    "num_class = 2\n",
    "drop = 0.1\n",
    "lr = 0.0001\n",
    "num_epochs = 100\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d4d5e6-766b-4d39-a099-de06c4c94281",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=my_Dataset('./data_ROI/feature1.npy','./data_ROI/feature2.npy','./data_ROI/label.npy')\n",
    "train_iter=DataLoader(dataset,\n",
    "                      batch_size = batch_size,\n",
    "                      shuffle=True,\n",
    "                      pin_memory=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = attentionmerge(data_len, middle_dim, drop, num_class)\n",
    "optimizer = configure_optimizers(model, lr=lr, weight_decay=0.1)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666c9644-5051-476b-a23a-ed2b8574a310",
   "metadata": {},
   "source": [
    "模型预览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187ace7e-fa6c-4eae-9e14-523bf6a829bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"number of parameters: %.2fM\" % (n_params/1e6,))\n",
    "# 输出参数量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b499f60-e9f7-43c9-bde3-555ade92f01f",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c6183a-198f-4300-a281-74d628bf1ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.apply(_init_weights)\n",
    "    for pn, p in model.named_parameters():\n",
    "        if pn.endswith('c_proj.weight'):\n",
    "            torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2))\n",
    "\n",
    "    train(train_iter, model, criterion, epoch)\n",
    "    test_acc = evaluate_accuracy_gpu(model, train_iter)\n",
    "    print(\"Epoch [{}]  accuracy: {:.5f}\".format(epoch, test_acc))\n",
    "    f = open(\"training_data_attention.txt\", \"a\")\n",
    "    f.write(\"Epoch [{}]  accuracy: {:.5f}\".format(epoch, test_acc)+'\\n')\n",
    "    f.close()\n",
    "    torch.save(model, './checkpoint_attention/checkpoint_' + str(epoch) + '.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
